# -*- coding: utf-8 -*-
"""Linearidade_160825.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/101CaC5GhH-1XeGecH_Ylk0FhQrnzvT9m

# Tratamento Estatísticos - Validação Analítica

##1 - Introdução

A linearidade de um procedimento analítico é a sua capacidade de obter resultados que sejam diretamente proporcionais à concentração de um analito em uma amostra.

##2 - Coleta de Dados

A seguir, apresentam-se os dados coletados:
"""

# Incluir os valores encontrados, na ordem: Concentração; Área; Nível; Ordem de Coleta

dados = [
    [0.157043,4660341,1,14],
    [0.160399,4754809,1,12],
    [0.160879,4681500,1,2],
    [0.176673,5384404,2,7],
    [0.180449,5428730,2,4],
    [0.180989,5263780,2,15],
    [0.196304,5843775,3,10],
    [0.200499,5993295,3,1],
    [0.201099,5841594,3,11],
    [0.215934,6555505,4,8],
    [0.220549,6607388,4,6],
    [0.221209,6294577,4,3],
    [0.235564,7109287,5,9],
    [0.240599,7181692,5,5],
    [0.241318,7095422,5,13],
]

print(dados)

df_cabeçalho.head(1)

## Instalar as bibliotecas

# !pip install numpy
# !pip install pandas
# !pip install matplotlib
# !pip install seaborn
# !pip install scipy
# !pip install streamlit

# != é diferente
# ! significa que o comando está sendo executando nesse ambiente

!pip install -q streamlit

"""# Criação de um exemplo"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# 
# x = st.slider('Select a value')
# st.write(x, 'squared is', x * x)

import pandas as pd

# Utilizar as opções da biblioteca pandas para padronizar os resultados obtidos do tipo float com uma casa decimal.
pd.options.display.float_format = '{:.1f}'.format

print("Pandas display options for float format have been set to one decimal place.")

## Importar as bibliotecas
# Processamento de dados

import numpy as np # ela é utilizada para cálculo númerico e vetorial
import pandas as pd # utilizada para dataframet e processamento de dados

# Processamento de dataviz - gerar gráficos
import matplotlib.pyplot as plt # gerar gráficos
import seaborn as sns # gerar gráficos melhorados

# Processamento estatístico e ML
from scipy.stats import f_oneway

"""Tabela 1 - Conjunto de dados para o estudo de Linearidade"""

import pandas as pd
df_cabeçalho = pd.DataFrame(dados, columns=['Concentração mg/mL', 'Área', 'Nível', 'Ordem de Coleta'])

df_cabeçalho

"""##3 - Método dos Mínimos Quadrados Ordinários: Estimação

O Método dos Mínimos Quadrados é uma eficiente estratégia de estimação dos parâmetros da regressão e sua aplicação não é limitada apenas às relações lineares. Nesta seção utilizamos o Método dos Mínimos Quadrados Ordinários.

##3.1 - Teste do Coeficiente Angular
Para avaliar a significância do modelo utilizamos o teste F da ANOVA. Neste caso, testa-se as hipóteses:

H0: coeficiente angular igual a zero;

H1: coeficiente angular diferente de zero.
"""

import pandas as pd
df_cabeçalho = pd.DataFrame(dados, columns=['Concentração mg/mL', 'Área', 'Nível', 'Ordem de Coleta'])

df_cabeçalho.columns

"""Tabela 2 - Tabela da ANOVA"""

import statsmodels.api as sm
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
import pandas as pd

# Define the dataframe
dados = df_cabeçalho = pd.DataFrame(dados, columns=['Concentração mg/mL', 'Área', 'Nível', 'Ordem de Coleta'])


# Fit the OLS model
# Ensure the column name is correctly quoted if it contains spaces or special characters
model_sm = ols('Área ~ Q("Concentração mg/mL")', data=df_cabeçalho).fit()

# Perform ANOVA test
anova_table = anova_lm(model_sm)

# Select relevant rows and columns for the summary table
anova_summary = anova_table.loc[['Q("Concentração mg/mL")', 'Residual'],
                                ['df', 'sum_sq', 'mean_sq', 'F', 'PR(>F)']]

# Rename columns for clarity
anova_summary.columns = ['Graus de Liberdade', 'Soma dos Quadrados', 'Quadrado Médio', 'Estatística F', 'P-valor']

# Display the ANOVA summary table
print("Tabela ANOVA para Regressão Linear:")
display(anova_summary)

# Interpret the p-value
alpha = 0.05
p_value_concentration = anova_summary.loc['Q("Concentração mg/mL")', 'P-valor']

print("\nInterpretação do Teste F da ANOVA:")
if p_value_concentration < alpha:
    print(f"Como o P-valor ({p_value_concentration:.4f}) é menor que {alpha}, rejeitamos a hipótese nula (coeficiente angular igual a zero) ao nível de significância de 5%.")
    print("Conclusão: O coeficiente angular é estatisticamente diferente de zero, indicando que a Concentração mg/mL é um preditor significativo da Área.")
else:
    print(f"Como o P-valor ({p_value_concentration:.4f}) não é menor que {alpha}, falhamos em rejeitar a hipótese nula (coeficiente angular igual a zero) ao nível de significância de 5%.")
    print("Conclusão: Não há evidência estatística suficiente para concluir que o coeficiente angular é diferente de zero.")

"""As estimativas dos parâmetros (coeficientes de regressão) e seus respectivos intervalos de confiança de 95% são:

Tabela 3 - Coeficientes
"""

import pandas as pd

# Assuming the 'model_sm' variable from cell TcUvkEEmfOIv holds the statsmodels OLS model
# If not, you would need to fit the model again:
# model_sm = ols('Área ~ Q("Concentração mg/mL")', data=df_cabeçalho).fit()

# Get the regression results summary
results_summary = model_sm.summary2().tables[1]

# Extract the relevant rows for Intercept and Q("Concentração mg/mL")
coefficients_table = results_summary.loc[['Intercept', 'Q("Concentração mg/mL")'],
                                         ['Coef.', 'Std.Err.', 't', 'P>|t|']]

# Rename columns for clarity
coefficients_table.columns = ['Estimativa', 'Desvio Padrão', 'Estatística t', 'P-valor']

import pandas as pd

# Set pandas options to display floats with one decimal place
pd.options.display.float_format = '{:.4f}'.format

print("Pandas display options for float format have been set to one decimal place.")

print("Tabela de Coeficientes:")
display(coefficients_table)

"""Tabela 4 - Intervalo de confiança para os parâmetros"""

import pandas as pd

# Assuming the 'model_sm' variable from cell 9hv9fsWIlgyu holds the statsmodels OLS model
# If not, you would need to fit the model again:
# model_sm = ols('Área ~ Q("Concentração mg/mL")', data=df_cabeçalho).fit()

# Get the regression results summary
results_summary = model_sm.summary2().tables[1]

# Extract the relevant rows for Intercept and Q("Concentração mg/mL") and columns for confidence intervals
confidence_interval_table = results_summary.loc[['Intercept', 'Q("Concentração mg/mL")'],
                                                ['Coef.', '[0.025', '0.975]']]

# Rename columns for clarity (assuming a 95% confidence interval by default)
confidence_interval_table.columns = ['Estimativa', 'Lower 95% CI', 'Upper 95% CI']

# Set pandas options to display floats with one decimal place
pd.options.display.float_format = '{:.4f}'.format

print("Tabela de Intervalos de Confiança:")
display(confidence_interval_table)

"""##3.2 - Teste do Intercepto (Coeficiente Linear)

Para avaliarmos o intercepto (coeficiente linear) utiliza-se a estatística t de Student. Neste caso, testamos as hipóteses:

H0: intercepto (coeficiente linear) igual a zero;

H1: intercepto diferente de zero.
"""

import pandas as pd

# Assuming the 'model_sm' variable from cell 9hv9fsWIlgyu holds the statsmodels OLS model
# If not, you would need to fit the model again:
# model_sm = ols('Área ~ Q("Concentração mg/mL")', data=df_cabeçalho).fit()

# Get the summary of the fitted model
model_summary = model_sm.summary2().tables[1]

# Extract the p-value for the Intercept
intercept_p_value = model_summary.loc['Intercept', 'P>|t|']

# Define the significance level
alpha = 0.05

# Print the p-value and conclusion
print(f"P-valor para o Intercepto: {intercept_p_value:.4f}")

print("\nInterpretação do Teste t para o Intercepto:")
if intercept_p_value > alpha:
    print(f"Como o P-valor ({intercept_p_value:.4f}) é maior que {alpha}, falhamos em rejeitar a hipótese nula (intercepto igual a zero) ao nível de significância de 5%.")
    print("Conclusão: Não há evidência estatística suficiente para concluir que o intercepto é diferente de zero.")
else:
    print(f"Como o P-valor ({intercept_p_value:.4f}) é menor ou igual a {alpha}, rejeitamos a hipótese nula (intercepto igual a zero) ao nível de significância de 5%.")
    print("Conclusão: O intercepto é estatisticamente diferente de zero.")

"""##3.3 - Impacto do Coeficiente Linear (Intercepto)

Tabela 5 - Medida descritiva da qualidade do ajuste
"""

import pandas as pd
import numpy as np
from scipy.stats import pearsonr
import statsmodels.api as sm
from sklearn.linear_model import LinearRegression

# Assuming 'df_cabeçalho' is your pandas DataFrame
# Assuming 'Concentração mg/mL' is the independent variable and 'Área' is the dependent variable

# Fit a linear regression model using sklearn to easily get residuals and R-squared
# We use sklearn here for simplicity in getting R-squared and residuals for standard deviation calculation.
# The statsmodels 'model_sm' fitted earlier can also be used for these values.
X = df_cabeçalho[['Concentração mg/mL']]
y = df_cabeçalho['Área']

model_sklearn = LinearRegression()
model_sklearn.fit(X, y)

# Get the residuals from the sklearn model
residuals = y - model_sklearn.predict(X)

# Calculate the standard deviation of residuals
# Use ddof=model_sklearn.rank_ for the unbiased estimator (n - p)
std_dev_residuals = np.std(residuals, ddof=model_sklearn.rank_)

# Get the degrees of freedom for the residuals
# For simple linear regression, df = n - p - 1, where n is number of observations and p is number of predictors (1)
n = len(df_cabeçalho)
p = X.shape[1]
degrees_freedom = n - p - 1

# Get R-squared from the sklearn model
r_squared = model_sklearn.score(X, y)

# Calculate the Pearson correlation coefficient between 'Concentração mg/mL' and 'Área'
correlation_coefficient, _ = pearsonr(df_cabeçalho['Concentração mg/mL'], df_cabeçalho['Área'])

# Create a DataFrame for the summary table
summary_of_fit_df = pd.DataFrame({
    'Measure': [
        'Desvio Padrão dos Resíduos',
        'Graus de Liberdade',
        'R Quadrado (R²)',
        'Coeficiente de Correlação de Pearson'
    ],
    'Value': [
        std_dev_residuals,
        degrees_freedom,
        r_squared,
        correlation_coefficient
    ]
})

# Set pandas options to display floats with a reasonable number of decimal places
pd.options.display.float_format = '{:.4f}'.format

print("Tabela - Medida Descritiva da Qualidade do Ajuste:")
display(summary_of_fit_df)

# Conclude based on the correlation coefficient
correlation_threshold = 0.9900

print("\nConclusão sobre o Coeficiente de Correlação de Pearson:")
if correlation_coefficient > correlation_threshold:
    print(f"O coeficiente de correlação de Pearson ({correlation_coefficient:.4f}) é maior que {correlation_threshold:.4f}.")
    print("Conclusão: Existe uma relação linear adequada entre Concentração mg/mL e Área.")
else:
    print(f"O coeficiente de correlação de Pearson ({correlation_coefficient:.4f}) não é maior que {correlation_threshold:.4f}.")
    print("Conclusão: Não há evidência suficiente para concluir que existe uma relação linear adequada (com base no critério > 0.9900).")

import statsmodels.api as sm
from statsmodels.formula.api import ols

# Assuming 'df_cabeçalho' is your pandas DataFrame
# Assuming 'Concentração mg/mL' is your independent variable and 'Área' is your dependent variable

# Fit the OLS model using statsmodels
model_sm = ols('Área ~ Q("Concentração mg/mL")', data=df_cabeçalho).fit()

# Display the regression summary
print(model_sm.summary())

"""##4 - Análise Gráfica

##4.1 - Diagrama de dispersão

O diagrama de dispersão é um gráfico que permite a visualização de uma possível associação entre variáveis quantitativas.

Figura 1 - Diagrama de Dispersão
"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import statsmodels.api as sm
from statsmodels.sandbox.regression.predstd import wls_prediction_std

# Assuming 'df_cabeçalho' is your pandas DataFrame
# Assuming 'model_sm' holds the fitted statsmodels OLS model

# Get the fitted values from the model
fitted_values = model_sm.fittedvalues

# Get the standard deviation of the prediction
# prstd, iv_l, iv_u = wls_prediction_std(model_sm) # Prediction interval
prstd, iv_l_mean, iv_u_mean = wls_prediction_std(model_sm, alpha=0.05) # Confidence interval for the mean response

plt.figure(figsize=(6, 4))

# Create a scatter plot of the original data points
sns.scatterplot(data=df_cabeçalho, x='Concentração mg/mL', y='Área', label='Original Data')

# Add the fitted regression line
plt.plot(df_cabeçalho['Concentração mg/mL'], fitted_values, color='red', label='Fitted Line')

# Add the 95% Confidence Interval lines for the mean response
plt.plot(df_cabeçalho['Concentração mg/mL'], iv_l_mean, color='green', linestyle='--', label='Lower 95% CI for Mean')
plt.plot(df_cabeçalho['Concentração mg/mL'], iv_u_mean, color='purple', linestyle='--', label='Upper 95% CI for Mean')


plt.title('Diagrama de Dispersão: Concentração vs Área com Linha de Tendência e Intervalo de Confiança')
plt.xlabel('Concentração mg/mL')
plt.ylabel('Área')
plt.grid(True)
plt.legend()
plt.show()

print("The dashed green and purple lines represent the lower and upper bounds of the 95% confidence interval for the mean response, respectively. This might be what was intended by 'two more lines in the diagonal that are the adjusted values'.")

# @title Diagrama de Dispersão

from matplotlib import pyplot as plt
import seaborn as sns # Import seaborn

df_cabeçalho.plot(kind='scatter', x='Concentração mg/mL', y='Área', s=32, alpha=.8)
# Add the regression line
sns.regplot(data=df_cabeçalho, x='Concentração mg/mL', y='Área', scatter=False, color='red', marker='o')
plt.gca().spines[['top', 'right',]].set_visible(False)
plt.title('Diagrama de Dispersão')
plt.xlabel('Concentração (mg/mL)')
plt.ylabel('Área')
plt.grid()
plt.show()

"""## 4.2 - Diagnóstico dos Resíduos do Modelo

I - Gráfico de Resíduos padronizados vs Valores ajustados: é usado para detectar se os resíduos se distribuem aleatoriamente e para detectar a presença de valores extremos (outliers) nos dados. Geralmente, consideram-se outliers os pontos que excedem o limite de 3 desvios padrão.

Figura 2 - Gráficos da Análise dos Resíduos.
"""

# 1. Resíduos Padronizados vs. Valores Ajustados
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm

# Assuming the 'model_sm' variable from cell 9hv9fsWIlgyu holds the statsmodels OLS model
# If not, you would need to fit the model again:
# model_sm = ols('Área ~ Q("Concentração mg/mL")', data=df_cabeçalho).fit()

# Get the fitted values from the statsmodels OLS model
fitted_values = model_sm.fittedvalues

# Get standardized residuals (internally studentized)
standardized_residuals = model_sm.get_influence().resid_studentized_internal

plt.figure(figsize=(8, 4))
sns.scatterplot(x=fitted_values, y=standardized_residuals)
plt.axhline(y=0, color='r', linestyle='--') # Add line at 0
plt.axhline(y=2, color='blue', linestyle='--') # Add line at +2
plt.axhline(y=-2, color='blue', linestyle='--') # Add line at -2
plt.axhline(y=3, color='red', linestyle='--') # Add line at +3
plt.axhline(y=-3, color='red', linestyle='--') # Add line at -3
plt.title('Resíduos Padronizados vs. Valores Ajustados')
plt.xlabel('Valores Ajustados')
plt.ylabel('Resíduos Padronizados')
plt.grid(True)
plt.show()

"""II - Gráfico de Resíduos da Normal: é usado para verificar a pressuposição de que os resíduos são distribuídos normalmente. Em caso de normalidade os resíduos em geral seguem aproximadamente uma linha reta."""

# QQ-Plot dos Resíduos
import matplotlib.pyplot as plt
import statsmodels.api as sm

# Assuming the 'model_sm' variable from cell 9hv9fsWIlgyu holds the statsmodels OLS model
# Get the residuals from the fitted model
residuals = model_sm.resid

plt.figure(figsize=(6, 4))
# Create the QQ-plot without confidence bands, just the points and a reference line
sm.qqplot(residuals, line='s') # 's' for standardized line
plt.title('QQ-Plot dos Resíduos')
plt.xlabel('Quantis Teóricos da Distribuição Normal')
plt.ylabel('Quantis da Amostra (Resíduos)')
plt.grid(True)
plt.show()

"""III - Gráfico de Resíduos vs Valores ajustados: é usado para verificar a pressuposição de que os resíduos se distribuem aleatoriamente e que tem variância constante."""

# 3. Resíduos vs. Valores Ajustados
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm

# Get the fitted values from the statsmodels OLS model
# Assuming the 'model_sm' variable from cell TcUvkEEmfOIv holds the statsmodels OLS model
fitted_values = model_sm.fittedvalues

# Get the residuals from the fitted model
# Assuming the 'model_sm' variable from cell TcUvkEEmfOIv holds the statsmodels OLS model
residuals = model_sm.resid

plt.figure(figsize=(6, 4))
sns.scatterplot(x=fitted_values, y=residuals)
plt.axhline(y=0, color='r', linestyle='--') # Add line at 0
plt.title('Resíduos vs. Valores Ajustados')
plt.xlabel('Valores Ajustados')
plt.ylabel('Resíduos')
plt.grid(True)
plt.show()

"""IV - Gráfico de Resíduos vs Ordem de coleta: este gráfico mostra os resíduos na ordem em que foram coletados e é usado para verificar a pressuposição de independência. Em geral, para que se cumpra tal requisito, os dados devem se dispor aleatoriamente em torno da linha central."""

# 4. Resíduos vs. Ordem de Coleta
plt.figure(figsize=(6, 4))
sns.scatterplot(x=df_cabeçalho['Ordem de Coleta'], y=residuals)
sns.lineplot(x=df_cabeçalho['Ordem de Coleta'], y=residuals)
plt.axhline(y=0, color='r', linestyle='--') # Add line at 0
plt.title('Resíduos vs. Ordem de Coleta')
plt.xlabel('Ordem de Coleta')
plt.ylabel('Resíduos')
plt.grid(True)
plt.show()

"""## 5 - Avaliação dos Resíduos

## 5.1 - Avaliação da Normalidade: teste de Shapiro-Wilk

Para avaliar estatisticamente a normalidade dos resíduos realiza-se o seguinte teste de hipóteses:

H0: a distribuição dos resíduos é Normal;

H1: a distribuição dos resíduos não é Normal.
"""

import scipy.stats as stats
import pandas as pd

# Assuming 'residuals' variable holds the residuals from the fitted model
# If not, you would need to calculate or get the residuals first.
# For example, if you have a statsmodels model object named 'model_sm':
# residuals = model_sm.resid

# Perform the Shapiro-Wilk test for normality
shapiro_test_statistic, shapiro_p_value = stats.shapiro(residuals)

# Create a DataFrame to display the results
shapiro_results_df = pd.DataFrame({
    'Test Performed': ["Shapiro-Wilk Test for Normality of Residuals"],
    'Test Statistic': [shapiro_test_statistic],
    'P-value': [shapiro_p_value]
})

# Set pandas options to display floats with a reasonable number of decimal places
pd.options.display.float_format = '{:.4f}'.format

print("Shapiro-Wilk Test Results for Residuals:")
display(shapiro_results_df)

# Interpret the p-value
alpha = 0.05

print("\nInterpretation:")
print("H0: A distribuição dos resíduos é Normal.")
print("H1: A distribuição dos resíduos não é Normal.")

if shapiro_p_value > alpha:
    print(f"Como o P-valor ({shapiro_p_value:.4f}) é maior que {alpha}, falhamos em rejeitar a hipótese nula (a distribuição dos resíduos é Normal) ao nível de significância de 5%.")
    print("Conclusão: Não há evidência estatística suficiente para concluir que a distribuição dos resíduos não é Normal. Assume-se normalidade dos resíduos.")
else:
    print(f"Como o P-valor ({shapiro_p_value:.4f}) é menor ou igual a {alpha}, rejeitamos a hipótese nula (a distribuição dos resíduos é Normal) ao nível de significância de 5%.")
    print("Conclusão: Há evidência estatística para concluir que a distribuição dos resíduos não é Normal.")

"""
## 5.2 - Avaliação da Homocedasticidade:  Teste de Cochran

Para avaliarmos a homocedasticidade da variância realiza-se o seguinte teste de hipóteses:

H0: Variâncias dos níveis são iguais;
H1: Pelo menos uma variância diferente.

A seguir, apresentamos o teste de Teste de Cochran."""

import pandas as pd
import numpy as np
from scipy.stats import f

# Assuming 'df_cabeçalho' is your pandas DataFrame
# Assuming 'Nível' is the grouping variable and 'Área' is the variable to test for homoscedasticity

# Group data by 'Nível' and calculate variances of 'Área'
grouped_variances = df_cabeçalho.groupby('Nível')['Área'].var().reset_index()
grouped_variances.rename(columns={'Área': 'Variance'}, inplace=True)

# Get the maximum variance
max_variance = grouped_variances['Variance'].max()

# Get the sum of variances
sum_of_variances = grouped_variances['Variance'].sum()

# Calculate Cochran's C statistic
cochran_c_statistic = max_variance / sum_of_variances

# Number of groups (k) and replicates per group (n)
k = len(grouped_variances) # Number of levels
n = 3 # Number of replicates per level, as specified by the user

# Calculate p-value for Cochran's C test (approximate method using F distribution)
# This is an approximation and might not be as accurate as using exact tables or dedicated functions.
# For a more precise p-value, dedicated statistical libraries or tables for Cochran's C are recommended.
# Using an approximation based on the maximum variance and average variance:
# F-statistic approximation: ((n-1)*C) / (1-C) where C is Cochran's C
if cochran_c_statistic < 1: # Ensure C is less than 1 for the formula
    f_approx = ((n - 1) * cochran_c_statistic) / (1 - cochran_c_statistic)
    # Degrees of freedom for the approximation: df1 = k-1, df2 = k*(n-1)
    df1 = k - 1
    df2 = k * (n - 1)
    # Calculate the approximate p-value (upper tail)
    p_value_cochran = 1 - f.cdf(f_approx, df1, df2)
else:
    p_value_cochran = 0.0 # If C >= 1, it's highly likely to reject H0

# Create a DataFrame for the results
cochran_results_df = pd.DataFrame({
    'Test Performed': ["Cochran's C Test for Homoscedasticity"],
    'Test Statistic': [cochran_c_statistic],
    'Number of Replicates (n)': [n],
    'Approximate P-value': [p_value_cochran]
})

# Add the conclusion
alpha = 0.05
print("\nHypotheses for Cochran's C Test:")
print("H0: Variances of the levels are equal (Homoscedasticity)")
print("H1: At least one variance is different (Heteroscedasticity)")


print("\nCochran's C Test Results:")
# Set pandas options to display floats with a reasonable number of decimal places for the statistic
pd.options.display.float_format = '{:.4f}'.format
display(cochran_results_df)


print("\nInterpretation:")
if p_value_cochran < alpha:
    print(f"As the approximate P-valor ({p_value_cochran:.4f}) é menor que {alpha}, rejeitamos a hipótese nula (Variâncias dos níveis são iguais) ao nível de significância de 5%.")
    print("Conclusão: Há evidência estatística para concluir que pelo menos uma variância é diferente. Logo, temos um modelo heterocedástico.")
else:
    print(f"As the approximate P-valor ({p_value_cochran:.4f}) não é menor que {alpha}, falhamos em rejeitar a hipótese nula (Variâncias dos níveis são iguais) ao nível de significância de 5%.")
    print("Conclusão: Não há evidência estatística suficiente para concluir que as variâncias são diferentes. Assume-se homoscedasticidade.")

"""## 6 - Valores extremos na resposta

Nesta seção, avalia-se os valores extremos (outliers) na resposta. Para isso, analisa-se os resíduos padronizados.

## 6.1 - Resíduos

Como critério, são considerados valores extremos nas resposta, as observações com resíduos padronizados maiores que 3.

Tabela 8 - Resumo da Análise dos Resíduos
"""

import pandas as pd

# Get the residuals from the fitted model (using the statsmodels OLS model)
# Assuming the 'model_sm' variable from cell TcUvkEEmfOIv holds the statsmodels OLS model
residuals = model_sm.resid

# Get standardized residuals (internally studentized)
standardized_residuals = model_sm.get_influence().resid_studentized_internal

# Get studentized residuals (externally studentized)
studentized_residuals = model_sm.get_influence().resid_studentized

# Create a DataFrame to display the residuals
residuals_df = pd.DataFrame({
    'Residuals': residuals,
    'Standardized Residuals': standardized_residuals,
    'Studentized Residuals': studentized_residuals
})

# Display the DataFrame
display(residuals_df)

import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm

# Assuming the 'model_sm' variable from cell 9hv9fsWIlgyu holds the statsmodels OLS model
# Get the fitted values from the statsmodels OLS model
fitted_values = model_sm.fittedvalues

# Calculate standardized residuals
standardized_residuals = model_sm.get_influence().resid_studentized_internal

# 1. Standardized Residuals vs. Fitted Values Plot
plt.figure(figsize=(8, 4))
sns.scatterplot(x=fitted_values, y=standardized_residuals)
plt.axhline(y=0, color='r', linestyle='--') # Add line at 0
plt.axhline(y=2, color='blue', linestyle='--') # Add line at +2
plt.axhline(y=-2, color='blue', linestyle='--') # Add line at -2
plt.axhline(y=3, color='red', linestyle='--') # Add line at +3
plt.axhline(y=-3, color='red', linestyle='--') # Add line at -3
plt.title('Resíduos Padronizados vs. Valores Ajustados')
plt.xlabel('Valores Ajustados')
plt.ylabel('Resíduos Padronizados')
plt.grid(True)
plt.show()

# 3. Resíduos vs. Valores Ajustados
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm

# Get the fitted values from the statsmodels OLS model
# Assuming the 'model_sm' variable from cell TcUvkEEmfOIv holds the statsmodels OLS model
fitted_values = model_sm.fittedvalues

# Get the residuals from the fitted model
# Assuming the 'model_sm' variable from cell TcUvkEEmfOIv holds the statsmodels OLS model
residuals = model_sm.resid

plt.figure(figsize=(6, 4))
sns.scatterplot(x=fitted_values, y=residuals)
plt.axhline(y=0, color='r', linestyle='--') # Add line at 0
plt.title('Resíduos vs. Valores Ajustados')
plt.xlabel('Valores Ajustados')
plt.ylabel('Resíduos')
plt.grid(True)
plt.show()

"""## 7 - Teste de Independência

Neste item testamos a independência das observações através do seguinte teste de hipóteses:

H0: Observações são independentes;

H1: Observações não são independentes.
"""

import pandas as pd
import statsmodels.api as sm

# Assuming the 'model_sm' variable from cell TcUvkEEmfOIv holds the statsmodels OLS model
# If not, you would need to fit the model again:
# model_sm = ols('Área ~ Q("Concentração mg/mL")', data=df_cabeçalho).fit()

# Get the Durbin-Watson statistic from the model summary
# This accesses the statistic from the summary table as demonstrated in the previous successful cell.
try:
    durbin_watson_statistic = model_sm.get_robustcov_results(cov_type='HC1').summary().tables[0].data[6][1]
    # Attempt to convert to float for display and comparison
    durbin_watson_statistic_float = float(durbin_watson_statistic)
except (AttributeError, IndexError, KeyError, ValueError, TypeError):
    durbin_watson_statistic = "Could not retrieve statistic"
    durbin_watson_statistic_float = None


# Create a DataFrame for display. Note: No standard p-value is directly available.
durbin_watson_df = pd.DataFrame({
    'Test Performed': ["Durbin-Watson Test for Independence of Observations"],
    'Test Statistic': [durbin_watson_statistic],
    'Note on P-value': ["A p-valor padrão não é fornecido diretamente na saída do summary2() para este teste. A interpretação formal requer valores críticos."]
})

print("Durbin-Watson Test Results:")
display(durbin_watson_df)

print("\nInterpretation:")
print("A estatística de Durbin-Watson varia de 0 a 4.")
print("- Um valor próximo a 2 sugere que não há autocorrelação nos resíduos (observações são independentes).")
print("- Um valor significativamente menor que 2 sugere autocorrelação positiva.")
print("- Um valor significativamente maior que 2 sugere autocorrelação negativa.")

if durbin_watson_statistic_float is not None:
    print(f"\nEstatística de Durbin-Watson obtida: {durbin_watson_statistic_float:.4f}")

    # Provide the standard interpretation based on the statistic's proximity to 2.
    # This is an approximate guideline, not a formal hypothesis test conclusion with a p-value.
    if durbin_watson_statistic_float > 1.5 and durbin_watson_statistic_float < 2.5:
         print("Conclusão (Baseada na Estatística): A estatística de Durbin-Watson está próxima de 2, sugerindo que não há evidência forte de autocorrelação nos resíduos.")
    else:
         print("Conclusão (Baseada na Estatística): A estatística de Durbin-Watson sugere possível autocorrelação nos resíduos. Recomenda-se consultar tabelas de valores críticos para uma conclusão formal com base no nível de significância de 5%.")
else:
    print("\nNão foi possível obter a estatística de Durbin-Watson para interpretação.")

print("\nPara uma conclusão formal ao nível de significância de 5%, compare a estatística de Durbin-Watson com os valores críticos de tabelas apropriadas para o tamanho da sua amostra e número de preditores.")

# 4. Resíduos vs. Ordem de Coleta
plt.figure(figsize=(6, 4))
sns.scatterplot(x=df_cabeçalho['Ordem de Coleta'], y=residuals)
sns.lineplot(x=df_cabeçalho['Ordem de Coleta'], y=residuals)
plt.axhline(y=0, color='r', linestyle='--') # Add line at 0
plt.title('Resíduos vs. Ordem de Coleta')
plt.xlabel('Ordem de Coleta')
plt.ylabel('Resíduos')
plt.grid(True)
plt.show()

"""## 8 - Resumo do estudo de linearidade

Para finalizarmos, apresentamos uma tabela com o resumo do estudo. O nível de significância utilizado para a conclusão que envolve teste estatístico é de 5%.
"""

# Get the estimated coefficients from the fitted model
# Assuming 'model_sm' holds the fitted statsmodels OLS model
intercept = model_sm.params['Intercept']
slope = model_sm.params['Q("Concentração mg/mL")']

# Display the equation of the line
print(f"Equação da Reta de Regressão:")
print(f"y = {intercept:.4f} + {slope:.4f} * Concentração mg/mL")

"""Tabela 10 - Resumo das conclusões do estudo de Linearidade (método dos mínimos quadrados ordinários)"""

alpha = 0.05

# 1. ANOVA F-test conclusion
if anova_p_value < alpha:
    anova_conclusion = "Model is statistically significant"
else:
    anova_conclusion = "Model is not statistically significant"

# 2. Intercept t-test conclusion
if intercept_p_value < alpha:
    intercept_conclusion = "Intercept is statistically significant"
else:
    intercept_conclusion = "Intercept is not statistically significant"

# 3. Concentration t-test conclusion
if concentration_p_value < alpha:
    concentration_conclusion = "Concentration coefficient is statistically significant"
else:
    concentration_conclusion = "Concentration coefficient is not statistically significant"

# 4. Anderson-Darling test conclusion for residuals
if ad_statistic > ad_critical_value_5:
    ad_conclusion = "Residuals do not appear normally distributed (at 5% significance level)"
else:
    ad_conclusion = "Residuals appear normally distributed (at 5% significance level)"

# 5. Cochran's C test conclusion for homoscedasticity
# Note: We cannot definitively conclude without a critical value table for Cochran's C.
# However, a high Cochran's C statistic (close to 1) suggests potential heteroscedasticity.
# A preliminary interpretation based on the value is provided.
# A more rigorous test would require comparing cochran_c_statistic to a critical value from a table.
# For a dataset with 5 groups and 3 replicates per group, the critical value at alpha=0.05
# is approximately 0.6839 according to some tables.
# Using this approximate value for preliminary interpretation:
approx_cochran_critical_value_05 = 0.6839

if cochran_c_statistic > approx_cochran_critical_value_05:
    cochran_conclusion = "Evidence of heteroscedasticity (based on preliminary comparison to approx. critical value)"
else:
    cochran_conclusion = "No strong evidence of heteroscedasticity (based on preliminary comparison to approx. critical value)"


print(f"ANOVA Conclusion: {anova_conclusion}")
print(f"Intercept Conclusion: {intercept_conclusion}")
print(f"Concentration Conclusion: {concentration_conclusion}")
print(f"Anderson-Darling Conclusion: {ad_conclusion}")
print(f"Cochran's C Conclusion: {cochran_conclusion}")

import pandas as pd

# Define the significance level
alpha = 0.05

# Recalculate conclusions for each test
# Ensure necessary variables from previous cells are available (e.g., anova_table, coefficients_table, ad_statistic, ad_critical_value_5, cochran_c_statistic)

# 1. ANOVA F-test conclusion
# Assuming anova_table is available from a previous executed cell (e.g., 9hv9fsWIlgyu)
if 'anova_table' in locals() and not anova_table.empty:
    if anova_table.loc['Q("Concentração mg/mL")', 'PR(>F)'] < alpha:
        anova_conclusion = "Model is statistically significant"
    else:
        anova_conclusion = "Model is not statistically significant"
else:
    anova_conclusion = "ANOVA results not available"

# 2. Intercept t-test conclusion
# Assuming coefficients_table is available from a previous executed cell (e.g., 75ybDfutrv3V or _h_gtRoMA09n)
if 'coefficients_table' in locals() and not coefficients_table.empty:
    if coefficients_table.loc['Intercept', 'P-valor'] < alpha:
        intercept_conclusion = "Intercept is statistically significant"
    else:
        intercept_conclusion = "Intercept is not statistically significant"
else:
    intercept_conclusion = "Intercept t-test results not available"

# 3. Concentration t-test conclusion
# Assuming coefficients_table is available
if 'coefficients_table' in locals() and not coefficients_table.empty:
    if coefficients_table.loc['Q("Concentração mg/mL")', 'P-valor'] < alpha:
        concentration_conclusion = "Concentration coefficient is statistically significant"
    else:
        concentration_conclusion = "Concentration coefficient is not statistically significant"
else:
    concentration_conclusion = "Concentration t-test results not available"


# 4. Anderson-Darling test conclusion for residuals
# Assuming ad_statistic and ad_critical_value_5 are available from a previous executed cell (e.g., 14220d2c)
# Note: Need to ensure cell 14220d2c or equivalent defining these variables is executed.
# If ad_statistic is defined:
if 'ad_statistic' in locals() and 'ad_critical_value_5' in locals():
    if ad_statistic > ad_critical_value_5:
        ad_conclusion = "Residuals do not appear normally distributed (at 5% significance level)"
    else:
        ad_conclusion = "Residuals appear normally distributed (at 5% significance level)"
elif 'shapiro_results_df' in locals() and not shapiro_results_df.empty:
     # Fallback to Shapiro-Wilk if Anderson-Darling results not available
     if shapiro_results_df.loc[0, 'P-value'] > alpha:
          ad_conclusion = f"Residuals appear normally distributed (Shapiro-Wilk P-value = {shapiro_results_df.loc[0, 'P-value']:.4f} > 0.05)."
     else:
          ad_conclusion = f"Residuals do not appear normally distributed (Shapiro-Wilk P-value = {shapiro_results_df.loc[0, 'P-value']:.4f} <= 0.05)."
else:
    ad_conclusion = "Normality test results not available"


# 5. Cochran's C test conclusion for homoscedasticity
# Assuming cochran_c_statistic and approx_cochran_critical_value_05 are available
# Let's use the approximate p-value from cochran_results_df (cell pdBveDINMhR9) as it was executed
if 'cochran_results_df' in locals() and not cochran_results_df.empty:
    if cochran_results_df.loc[0, 'Approximate P-value'] < alpha:
        cochran_conclusion = f"Evidence of heteroscedasticity (Approx. P-value = {cochran_results_df.loc[0, 'Approximate P-value']:.4f} < 0.05)"
    else:
        cochran_conclusion = f"No strong evidence of heteroscedasticity (Approx. P-value = {cochran_results_df.loc[0, 'Approximate P-value']:.4f} >= 0.05)"
else:
     cochran_conclusion = "Homoscedasticity test results not available"


# 6. Extreme Values in Response (based on Standardized Residuals)
# Assuming standardized_residuals is available from cell uuPd89kOgWuG or zSTSWc9zJU15
if 'standardized_residuals' in locals():
    if (standardized_residuals > 3).any() or (standardized_residuals < -3).any():
        extreme_values_conclusion = "Evidence of extreme values (outliers) in the response (> |3| standardized residuals)."
    else:
        extreme_values_conclusion = "No strong evidence of extreme values (outliers) in the response (all standardized residuals <= |3|)."
else:
     extreme_values_conclusion = "Standardized residuals not available for extreme value analysis."

# 7. Independence of Observations (Durbin-Watson)
# Assuming durbin_watson_statistic_float is available from cell af7_ADtjXjaB
if 'durbin_watson_statistic_float' in locals() and durbin_watson_statistic_float is not None:
    if durbin_watson_statistic_float > 1.5 and durbin_watson_statistic_float < 2.5:
         independence_conclusion = f"Durbin-Watson statistic ({durbin_watson_statistic_float:.4f}) is near 2, suggesting no strong autocorrelation."
    else:
         independence_conclusion = f"Durbin-Watson statistic ({durbin_watson_statistic_float:.4f}) suggests possible autocorrelation. Requires critical values for formal conclusion."
else:
     independence_conclusion = "Durbin-Watson test results not available."


# Create a list of test names (in Portuguese)
test_names = [
    "Teste F da ANOVA (Significância do Modelo)",
    "Teste t do Intercepto",
    "Coeficiente de Correlação de Pearson",
    "Teste de Normalidade dos Resíduos",
    "Teste de Homocedasticidade (Teste de Cochran)",
    "Valores Extremos na Resposta",
    "Teste de Independência das Observações (Durbin-Watson)"
]

# Create a list of corresponding conclusions
conclusions = [
    anova_conclusion,
    intercept_conclusion,
    concentration_conclusion,
    ad_conclusion,
    cochran_conclusion,
    extreme_values_conclusion,
    independence_conclusion
]

# Create the DataFrame
summary_table = pd.DataFrame({
    "Teste Realizado": test_names,
    "Conclusão": conclusions
})

# Set pandas options to display the full content of the conclusion column
pd.options.display.max_colwidth = None

print("Tabela Resumo das Conclusões do Estudo de Linearidade:")
display(summary_table)

"""## Display summary table

### Subtask:
Display the created summary table.

**Reasoning**:
Display the created summary table DataFrame.
"""

display(summary_table)

import numpy
import pandas
import matplotlib
import seaborn
import scipy

print(f"NumPy version: {numpy.__version__}")
print(f"Pandas version: {pandas.__version__}")
print(f"Matplotlib version: {matplotlib.__version__}")
print(f"Seaborn version: {seaborn.__version__}")
print(f"SciPy version: {scipy.__version__}")

!pip freeze > requirements.txt