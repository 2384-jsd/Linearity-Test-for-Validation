# -*- coding: utf-8 -*-
"""Linearidade_160825.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/101CaC5GhH-1XeGecH_Ylk0FhQrnzvT9m

# Tratamento Estatísticos Similares ao Sofware Action

A linearidade de um procedimento analítico é a sua capacidade de obter resultados que sejam diretamente proporcionais à concentração de um analito em uma amostra.

## 1 - Coleta de Dados
"""

# Incluir os valores encontrados, na ordem: Concentração; Área; Nível; Ordem de Coleta

dados = [
    [0.157043,4660341,1,14],
    [0.160399,4754809,1,12],
    [0.160879,4681500,1,2],
    [0.176673,5384404,2,7],
    [0.180449,5428730,2,4],
    [0.180989,5263780,2,15],
    [0.196304,5843775,3,10],
    [0.200499,5993295,3,1],
    [0.201099,5841594,3,11],
    [0.215934,6555505,4,8],
    [0.220549,6607388,4,6],
    [0.221209,6294577,4,3],
    [0.235564,7109287,5,9],
    [0.240599,7181692,5,5],
    [0.241318,7095422,5,13],
]

## Instalar as bibliotecas

# !pip install numpy
# !pip install pandas
# !pip install matplotlib
# !pip install seaborn
# !pip install scipy

# != é diferente
# ! significa que o comando está sendo executando nesse ambiente

## Importar as bibliotecas
# Processamento de dados

import numpy as np # ela é utilizada para cálculo númerico e vetorial
import pandas as pd # utilizada para dataframet e processamento de dados

# Processamento de dataviz - gerar gráficos
import matplotlib.pyplot as plt # gerar gráficos
import seaborn as sns # gerar gráficos melhorados

# Processamento estatístico e ML
from scipy.stats import f_oneway

"""## Tabela 1 - Conjunto de dados para Linearidade"""

import pandas as pd
df_cabeçalho = pd.DataFrame(dados, columns=['Concentração mg/mL', 'Área', 'Nível', 'Ordem de Coleta'])

df_cabeçalho

"""## 2 - Método dos Mínimos Quadrados Ordinários: Estimação
O Método dos Mínimos Quadrados é uma eficiente estratégia de estimação dos parâmetros da regressão e sua aplicação não é limitada apenas às relações lineares. Nesta seção utilizamos o Método dos Mínimos Quadrados Ordinários.

## 2.1 - Teste do Coeficiente Angular
Para avaliar a significância do modelo utilizamos o teste F da ANOVA. Neste caso, testamos as hipóteses:

H0: coeficiente angular igual a zero;

H1: coeficiente angular diferente de zero.
"""

import pandas as pd
df_cabeçalho = pd.DataFrame(dados, columns=['Concentração mg/mL', 'Área', 'Nível', 'Ordem de Coleta'])

df_cabeçalho.columns

"""## Tabela 2 - Tabela da ANOVA"""

import statsmodels.api as sm
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
import pandas as pd

# Define the dataframe
dados = df_cabeçalho = pd.DataFrame(dados, columns=['Concentração mg/mL', 'Área', 'Nível', 'Ordem de Coleta'])


# Fit the OLS model
# Ensure the column name is correctly quoted if it contains spaces or special characters
model_sm = ols('Área ~ Q("Concentração mg/mL")', data=df_cabeçalho).fit()

# Perform ANOVA test
anova_table = anova_lm(model_sm)

# Select relevant rows and columns for the summary table
anova_summary = anova_table.loc[['Q("Concentração mg/mL")', 'Residual'],
                                ['df', 'sum_sq', 'mean_sq', 'F', 'PR(>F)']]

# Rename columns for clarity
anova_summary.columns = ['Graus de Liberdade', 'Soma dos Quadrados', 'Quadrado Médio', 'Estatística F', 'P-valor']

# Display the ANOVA summary table
print("Tabela ANOVA para Regressão Linear:")
display(anova_summary)

# Interpret the p-value
alpha = 0.05
p_value_concentration = anova_summary.loc['Q("Concentração mg/mL")', 'P-valor']

print("\nInterpretação do Teste F da ANOVA:")
if p_value_concentration < alpha:
    print(f"Como o P-valor ({p_value_concentration:.4f}) é menor que {alpha}, rejeitamos a hipótese nula (coeficiente angular igual a zero) ao nível de significância de 5%.")
    print("Conclusão: O coeficiente angular é estatisticamente diferente de zero, indicando que a Concentração mg/mL é um preditor significativo da Área.")
else:
    print(f"Como o P-valor ({p_value_concentration:.4f}) não é menor que {alpha}, falhamos em rejeitar a hipótese nula (coeficiente angular igual a zero) ao nível de significância de 5%.")
    print("Conclusão: Não há evidência estatística suficiente para concluir que o coeficiente angular é diferente de zero.")

"""### As estimativas dos parâmetros (coeficientes de regressão) são respectivamente:

Tabela 4 - Coeficientes
"""

import pandas as pd

# Assuming the 'model_sm' variable from cell TcUvkEEmfOIv holds the statsmodels OLS model
# If not, you would need to fit the model again:
# model_sm = ols('Área ~ Q("Concentração mg/mL")', data=df_cabeçalho).fit()

# Get the regression results summary
results_summary = model_sm.summary2().tables[1]

# Extract the relevant rows for Intercept and Q("Concentração mg/mL")
coefficients_table = results_summary.loc[['Intercept', 'Q("Concentração mg/mL")'],
                                         ['Coef.', 'Std.Err.', 't', 'P>|t|']]

# Rename columns for clarity
coefficients_table.columns = ['Estimativa', 'Desvio Padrão', 'Estatística t', 'P-valor']

import pandas as pd

# Set pandas options to display floats with one decimal place
pd.options.display.float_format = '{:.4f}'.format

print("Pandas display options for float format have been set to one decimal place.")

print("Tabela de Coeficientes:")
display(coefficients_table)

"""### Tabela 5 - Intervalo de confiança para os parâmetros"""

import pandas as pd

# Assuming the 'model_sm' variable from cell TcUvkEEmfOIv holds the statsmodels OLS model
# If not, you would need to fit the model again:
# model_sm = ols('Área ~ Q("Concentração mg/mL")', data=df_cabeçalho).fit()

# Get the regression results summary
results_summary = model_sm.summary2().tables[1]

# Extract the relevant rows for Intercept and Q("Concentração mg/mL") and columns for confidence intervals
confidence_interval_table = results_summary.loc[['Intercept', 'Q("Concentração mg/mL")'],
                                                ['[0.025', '0.975]']]

# Rename columns for clarity (assuming a 95% confidence interval by default)
confidence_interval_table.columns = ['Lower 95% CI', 'Upper 95% CI']

# Set pandas options to display floats with one decimal place
pd.options.display.float_format = '{:.4f}'.format

print("Pandas display options for float format have been set to one decimal place.")

print("Tabela de Intervalos de Confiança:")
display(confidence_interval_table)

"""## 2.2 - Teste do Intercepto (Coeficiente Linear)

Para avaliarmos o intercepto (coeficiente linear) utilizamos a estatística t de Student. Neste caso, testamos as hipóteses:

H0: intercepto (coeficiente linear) igual a zero;

H1: intercepto diferente de zero.
"""

import pandas as pd

# Assuming the 'model_sm' variable from cell 9hv9fsWIlgyu holds the statsmodels OLS model
# If not, you would need to fit the model again:
# model_sm = ols('Área ~ Q("Concentração mg/mL")', data=df_cabeçalho).fit()

# Get the summary of the fitted model
model_summary = model_sm.summary2().tables[1]

# Extract the p-value for the Intercept
intercept_p_value = model_summary.loc['Intercept', 'P>|t|']

# Define the significance level
alpha = 0.05

# Print the p-value and conclusion
print(f"P-valor para o Intercepto: {intercept_p_value:.4f}")

print("\nInterpretação do Teste t para o Intercepto:")
if intercept_p_value > alpha:
    print(f"Como o P-valor ({intercept_p_value:.4f}) é maior que {alpha}, falhamos em rejeitar a hipótese nula (intercepto igual a zero) ao nível de significância de 5%.")
    print("Conclusão: Não há evidência estatística suficiente para concluir que o intercepto é diferente de zero.")
else:
    print(f"Como o P-valor ({intercept_p_value:.4f}) é menor ou igual a {alpha}, rejeitamos a hipótese nula (intercepto igual a zero) ao nível de significância de 5%.")
    print("Conclusão: O intercepto é estatisticamente diferente de zero.")

"""## 2.3 - Impacto do Coeficiente Linear (Intercepto)

Tabela 6 - Tabela Impacto do Coeficiente Linear (Intercepto)
"""

import pandas as pd
import numpy as np

# Assuming the 'model_sm' variable from cell TcUvkEEmfOIv holds the statsmodels OLS model
# Assuming 'df_cabeçalho' is your pandas DataFrame

# Get the estimated intercept from the fitted model
estimated_intercept = model_sm.params['Intercept']

# Get the predicted 'Área' values for each data point
predicted_area = model_sm.predict(df_cabeçalho['Concentração mg/mL'])

# Calculate the percentage impact of the intercept relative to the predicted value
# Handle cases where predicted_area might be zero or very close to zero to avoid division errors
percentage_impact_intercept = np.where(
    predicted_area != 0,
    (np.abs(estimated_intercept) / np.abs(predicted_area)) * 100,
    np.nan # Use NaN if predicted_area is zero
)

# Create a copy of the original DataFrame to add the new column
df_with_impact = df_cabeçalho.copy()

# Add the new column for the percentage impact of the intercept
df_with_impact['Impacto Coeficiente Linear (%)'] = percentage_impact_intercept

# Format the new column to 4 decimal places
df_with_impact['Impacto Coeficiente Linear (%)'] = df_with_impact['Impacto Coeficiente Linear (%)'].map('{:.4f}'.format)

# Display the resulting table
print("Tabela com Impacto do Coeficiente Linear:")
display(df_with_impact)

"""## 2.4 - Coeficiente de Correlação de Pearson
O coeficiente de correlação de Pearson mede o grau de proporcionalidade entre a variável explicativa e a variável resposta.

Tabela 7 - Medida Descritiva da Qualidade do Ajuste
"""

import numpy as np
import pandas as pd
from scipy.stats import pearsonr
import statsmodels.api as sm
from sklearn.linear_model import LinearRegression

# Sample data
X = df_cabeçalho[['Concentração mg/mL']] # Independent variable (as a DataFrame for 2D input)
y = df_cabeçalho['Área'] # Dependent variable

# Create and fit the linear regression model
model = LinearRegression()
model.fit(X, y)

# Pearson correlation coefficient
correlation_coefficient, _ = pearsonr(df_cabeçalho['Concentração mg/mL'], df_cabeçalho['Área'])
print(f"Pearson Correlation Coefficient: {correlation_coefficient}")

# Using the fitted sklearn model (from cell Bbud6faqiyEv)
# R-squared
r_squared = model.score(df_cabeçalho[['Concentração mg/mL']], df_cabeçalho['Área'])
print(f"R-squared: {r_squared}")

# Standard deviation of residuals
# The residuals are available from the sklearn model after fitting
residuals = df_cabeçalho['Área'] - model.predict(df_cabeçalho[['Concentração mg/mL']])
std_dev_residuals = np.std(residuals, ddof=model.rank_) # ddof=model.rank_ for unbiased estimator (n-p)
print(f"Standard Deviation of Residuals: {std_dev_residuals}")

# Degrees of freedom
# For a simple linear regression, df = n - p - 1, where n is number of observations and p is number of predictors
n = len(df_cabeçalho)
p = X.shape[1] # Number of independent variables
degrees_freedom = n - p - 1
print(f"Degrees of Freedom (Residuals): {degrees_freedom}")

# Note: The correlation coefficient is the same as the Pearson Correlation Coefficient in simple linear regression
print(f"Correlation Coefficient: {correlation_coefficient}")

"""Se o coeficiente de correlação for maior que 0.990 (conforme especificado), concluímos que  existe uma relação linear adequada.

## 3 - Análise Gráfica

## 3.1 - Diagrama de Dispersão
O diagrama de dispersão é um gráfico que permite a visualização de uma possível associação entre variáveis quantitativas.

Figura 1 - Diagrama de Dispersão
"""

# @title Concentração mg/mL vs Área

from matplotlib import pyplot as plt
import seaborn as sns # Import seaborn

df_cabeçalho.plot(kind='scatter', x='Concentração mg/mL', y='Área', s=32, alpha=.8)
sns.regplot(data=df_cabeçalho, x='Concentração mg/mL', y='Área', marker='o' )
plt.gca().spines[['top', 'right',]].set_visible(False)
plt.title('Concentração vs Área')
plt.xlabel('Concentração mg/mL')
plt.ylabel('Área')
plt.grid()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Create a scatter plot of 'Concentração mg/mL' vs 'Área'
plt.figure(figsize=(4, 2))
sns.scatterplot(data=df_cabeçalho, x='Concentração mg/mL', y='Área')

# Add the regression line
sns.regplot(data=df_cabeçalho, x='Concentração mg/mL', y='Área', scatter=False, color='red')

plt.title('Diagrama de Dispersão: Concentração vs Área')
plt.xlabel('Concentração mg/mL')
plt.ylabel('Área')
plt.grid(True)
plt.show()

"""## 3.2 - Diagnóstico dos Resíduos do Modelo

Figuras - Gráficos da Análise dos Resíduos.
"""

from sklearn.linear_model import LinearRegression
import numpy as np

# Sample data
X = df_cabeçalho[['Concentração mg/mL']] # Independent variable (as a DataFrame for 2D input)
y = df_cabeçalho['Área'] # Dependent variable

# Create and fit the linear regression model
model = LinearRegression()
model.fit(X, y)

# Access the intercept and coefficient
print("Intercept:", model.intercept_)
print("Coefficient:", model.coef_[0])

df_cabeçalho.head(1)

# 1. Resíduos Padronizados vs. Valores Ajustados
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm

# Get the fitted values from the statsmodels OLS model
# Assuming the 'model_sm' variable from cell TcUvkEEmfOIv holds the statsmodels OLS model
fitted_values = model_sm.fittedvalues

# Get the residuals from the fitted model
# Assuming the 'model_sm' variable from cell TcUvkEEmfOIv holds the statsmodels OLS model
residuals = model_sm.resid

plt.figure(figsize=(4, 2))
sns.scatterplot(x=fitted_values, y=residuals)
plt.axhline(y=0, color='r', linestyle='--') # Add line at 0
plt.title('Resíduos vs. Valores Ajustados')
plt.xlabel('Valores Ajustados')
plt.ylabel('Resíduos')
plt.grid(True)
plt.show()

# QQ-Plot dos Resíduos com Bandas de Confiança
import matplotlib.pyplot as plt
import statsmodels.api as sm

# Assuming the 'model_sm' variable from cell 9hv9fsWIlgyu holds the statsmodels OLS model
# Get the residuals from the fitted model
residuals = model_sm.resid

plt.figure(figsize=(1, 1))
# Create the QQ-plot with a reference line ('s' for standardized) and confidence bands ('r' for regression)
sm.qqplot(residuals, line='r') # 'r' for regression line through the quartiles
plt.title('QQ-Plot dos Resíduos com Bandas de Confiança')
plt.xlabel('Quantis Teóricos da Distribuição Normal')
plt.ylabel('Quantis da Amostra (Resíduos)')
plt.grid(True)
plt.show()

# 2. QQ-Plot dos Resíduos
plt.figure(figsize=(1, 1))
sm.qqplot(residuals, line='s') # 's' for standardized line
plt.title('QQ-Plot of Residuals')
plt.show()

# 4. Resíduos vs. Ordem de Coleta
plt.figure(figsize=(4, 2))
sns.scatterplot(x=df_cabeçalho['Ordem de Coleta'], y=residuals)
sns.lineplot(x=df_cabeçalho['Ordem de Coleta'], y=residuals)
plt.axhline(y=0, color='r', linestyle='--') # Add line at 0
plt.title('Resíduos vs. Ordem de Coleta')
plt.xlabel('Ordem de Coleta')
plt.ylabel('Resíduos')
plt.grid(True)
plt.show()

"""## Tabela 8 - Teste de Normalidade

H0: a distribuição dos resíduos é Normal;

H1: a distribuição dos resíduos não é Normal.
"""

import scipy.stats as stats
import pandas as pd

# Assuming 'residuals' variable holds the residuals from the fitted model
# If not, you would need to calculate or get the residuals first.
# For example, if you have a statsmodels model object named 'model_sm':
# residuals = model_sm.resid

# Perform the Shapiro-Wilk test for normality
shapiro_test_statistic, shapiro_p_value = stats.shapiro(residuals)

# Create a DataFrame to display the results
shapiro_results_df = pd.DataFrame({
    'Test Performed': ["Shapiro-Wilk Test for Normality of Residuals"],
    'Test Statistic': [shapiro_test_statistic],
    'P-value': [shapiro_p_value]
})

# Set pandas options to display floats with a reasonable number of decimal places
pd.options.display.float_format = '{:.4f}'.format

print("Shapiro-Wilk Test Results for Residuals:")
display(shapiro_results_df)

# Interpret the p-value
alpha = 0.05

print("\nInterpretation:")
print("H0: A distribuição dos resíduos é Normal.")
print("H1: A distribuição dos resíduos não é Normal.")

if shapiro_p_value > alpha:
    print(f"Como o P-valor ({shapiro_p_value:.4f}) é maior que {alpha}, falhamos em rejeitar a hipótese nula (a distribuição dos resíduos é Normal) ao nível de significância de 5%.")
    print("Conclusão: Não há evidência estatística suficiente para concluir que a distribuição dos resíduos não é Normal. Assume-se normalidade dos resíduos.")
else:
    print(f"Como o P-valor ({shapiro_p_value:.4f}) é menor ou igual a {alpha}, rejeitamos a hipótese nula (a distribuição dos resíduos é Normal) ao nível de significância de 5%.")
    print("Conclusão: Há evidência estatística para concluir que a distribuição dos resíduos não é Normal.")

import scipy.stats as stats
import pandas as pd

# Assuming the 'model_sm' variable from cell 9hv9fsWIlgyu holds the statsmodels OLS model
# Get the residuals from the fitted model
residuals = model_sm.resid

# Perform the Anderson-Darling test for normality
anderson_test_result = stats.anderson(residuals, dist='norm')

# Create a DataFrame to display the results
ad_results_df = pd.DataFrame({
    'Test Performed': ["Anderson-Darling Test for Normality of Residuals"],
    'Test Statistic': [anderson_test_result.statistic],
    'Critical Value (5%)': [anderson_test_result.critical_values[anderson_test_result.significance_level.tolist().index(5.0)]],
    'Significance Level (%)': [5.0]
})

# Add the conclusion
alpha = 0.05
if anderson_test_result.statistic > ad_results_df.loc[0, 'Critical Value (5%)']:
    ad_results_df['Conclusion'] = "Reject H0: Residuals are not normally distributed at 5% significance level."
else:
    ad_results_df['Conclusion'] = "Fail to reject H0: Residuals appear normally distributed at 5% significance level."


import pandas as pd

# Set pandas options to display floats without scientific notation
pd.options.display.float_format = '{:.4f}'.format

print("Pandas display options for float format have been set.")

print("Anderson-Darling Test Results for Residuals:")
display(ad_results_df)

"""## 4 - Avaliação da Homocedasticidade:  Teste de Cochran
Para avaliarmos a homocedasticidade da variância realizamos o seguinte teste de hipóteses:

H0: Variâncias dos níveis são iguais;
H1: Pelo menos uma variância diferente.

A seguir, apresentamos o teste de Teste de Cochran.
"""

import pandas as pd
import numpy as np
from scipy.stats import f

# Assuming 'df_cabeçalho' is your pandas DataFrame
# Assuming 'Nível' is the grouping variable and 'Área' is the variable to test for homoscedasticity

# Group data by 'Nível' and calculate variances of 'Área'
grouped_variances = df_cabeçalho.groupby('Nível')['Área'].var().reset_index()
grouped_variances.rename(columns={'Área': 'Variance'}, inplace=True)

# Get the maximum variance
max_variance = grouped_variances['Variance'].max()

# Get the sum of variances
sum_of_variances = grouped_variances['Variance'].sum()

# Calculate Cochran's C statistic
cochran_c_statistic = max_variance / sum_of_variances

# Number of groups (k) and replicates per group (n)
k = len(grouped_variances) # Number of levels
n = 3 # Number of replicates per level, as specified by the user

# Calculate p-value for Cochran's C test (approximate method using F distribution)
# This is an approximation and might not be as accurate as using exact tables or dedicated functions.
# For a more precise p-value, dedicated statistical libraries or tables for Cochran's C are recommended.
# Using an approximation based on the maximum variance and average variance:
# F-statistic approximation: ((n-1)*C) / (1-C) where C is Cochran's C
if cochran_c_statistic < 1: # Ensure C is less than 1 for the formula
    f_approx = ((n - 1) * cochran_c_statistic) / (1 - cochran_c_statistic)
    # Degrees of freedom for the approximation: df1 = k-1, df2 = k*(n-1)
    df1 = k - 1
    df2 = k * (n - 1)
    # Calculate the approximate p-value (upper tail)
    p_value_cochran = 1 - f.cdf(f_approx, df1, df2)
else:
    p_value_cochran = 0.0 # If C >= 1, it's highly likely to reject H0

# Create a DataFrame for the results
cochran_results_df = pd.DataFrame({
    'Test Performed': ["Cochran's C Test for Homoscedasticity"],
    'Test Statistic': [cochran_c_statistic],
    'Number of Replicates (n)': [n],
    'Approximate P-value': [p_value_cochran]
})

# Add the conclusion
alpha = 0.05
print("\nHypotheses for Cochran's C Test:")
print("H0: Variances of the levels are equal (Homoscedasticity)")
print("H1: At least one variance is different (Heteroscedasticity)")


print("\nCochran's C Test Results:")
# Set pandas options to display floats with a reasonable number of decimal places for the statistic
pd.options.display.float_format = '{:.4f}'.format
display(cochran_results_df)


print("\nInterpretation:")
if p_value_cochran < alpha:
    print(f"As the approximate P-valor ({p_value_cochran:.4f}) é menor que {alpha}, rejeitamos a hipótese nula (Variâncias dos níveis são iguais) ao nível de significância de 5%.")
    print("Conclusão: Há evidência estatística para concluir que pelo menos uma variância é diferente. Logo, temos um modelo heterocedástico.")
else:
    print(f"As the approximate P-valor ({p_value_cochran:.4f}) não é menor que {alpha}, falhamos em rejeitar a hipótese nula (Variâncias dos níveis são iguais) ao nível de significância de 5%.")
    print("Conclusão: Não há evidência estatística suficiente para concluir que as variâncias são diferentes. Assume-se homoscedasticidade.")

"""## 5 - Método dos Mínimos Quadrados Ponderados: Estimação

## 5.1 - Teste do Coeficiente Angular
Para avaliar a significância do modelo utilizamos o teste F da ANOVA. Neste caso, testamos as hipóteses:

H0: coeficiente angular igual a zero;

H1: coeficiente angular diferente de zero.

## Tabela 10 - Tabela da ANOVA
"""



"""## Tabela 11 - Análise exploratória (resíduos)

## Tabela 13 - Intervalo de confiança para os parâmetros

## 5.2 - Teste do Intercepto (coeficiente linear)

Para avaliarmos o intercepto (coeficiente linear) utilizamos a estatística t de Student. Neste caso, testamos as hipóteses:
H0: intercepto (coeficiente linear) igual a zero;

H1: intercepto diferente de zero.

## 5.3 - Impacto do Coeficiente Linear (intercepto)

## Tabela 14 - Impacto do Coeficiente Linear (Intercepto)
"""

import statsmodels.stats.api as sms

sms.het_breuschpagan = df_cabeçalho

print(sms.het_breuschpagan)

import statsmodels.api as sm
from statsmodels.formula.api import ols

# Assuming 'df_cabeçalho' is your pandas DataFrame
# Assuming 'Concentração mg/mL' is your independent variable and 'Área' is your dependent variable

# Fit the OLS model using statsmodels
model_sm = ols('Área ~ Q("Concentração mg/mL")', data=df_cabeçalho).fit()

# Display the regression summary
print(model_sm.summary())

import pandas as pd

# Get the residuals from the fitted model (using the statsmodels OLS model)
# Assuming the 'model_sm' variable from cell TcUvkEEmfOIv holds the statsmodels OLS model
residuals = model_sm.resid

# Get standardized residuals (internally studentized)
standardized_residuals = model_sm.get_influence().resid_studentized_internal

# Get studentized residuals (externally studentized)
studentized_residuals = model_sm.get_influence().resid_studentized

# Create a DataFrame to display the residuals
residuals_df = pd.DataFrame({
    'Residuals': residuals,
    'Standardized Residuals': standardized_residuals,
    'Studentized Residuals': studentized_residuals
})

# Display the DataFrame
display(residuals_df)

"""## 5.4 - Coeficiente de Correlação de Pearson
O coeficiente de correlação de Pearson mede o grau de proporcionalidade entre a variável explicativa e a variável resposta.
"""



"""## 6 - Análise Gráfica

## 6.1 - Diagrama de Dispersão
O diagrama de dispersão é um gráfico que permite a visualização de uma possível associação entre variáveis quantitativas.
"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Assuming 'df_cabeçalho' is your pandas DataFrame
# Assuming 'model_sm' holds the fitted statsmodels OLS model

# Get the fitted values from the model
fitted_values = model_sm.fittedvalues

# Get the residuals from the model
residuals = model_sm.resid

plt.figure(figsize=(6, 4))

# Create a scatter plot of the original data points
sns.scatterplot(data=df_cabeçalho, x='Concentração mg/mL', y='Área', label='Original Data')

# Add the fitted regression line
sns.lineplot(x=df_cabeçalho['Concentração mg/mL'], y=fitted_values, color='red', label='Fitted Line')

# Add perpendicular lines from each data point to the fitted line (representing residuals)
for i in range(len(df_cabeçalho)):
    plt.plot([df_cabeçalho['Concentração mg/mL'][i], df_cabeçalho['Concentração mg/mL'][i]],
             [df_cabeçalho['Área'][i], fitted_values[i]],
             color='gray', linestyle='--', linewidth=0.8)

plt.title('Diagrama de Dispersão com Resíduos')
plt.xlabel('Concentração mg/mL')
plt.ylabel('Área')
plt.grid(True)
plt.legend()
plt.show()

"""## 6.2 - Diagnósticos de Resíduos do Modelo"""

import scipy.stats as stats
import pandas as pd

# Assuming the 'model_sm' variable from cell 9hv9fsWIlgyu holds the statsmodels OLS model
# Get the residuals from the fitted model
residuals = model_sm.resid

# Perform the Anderson-Darling test for normality
anderson_test_result = stats.anderson(residuals, dist='norm')

# Create a DataFrame to display the results
ad_results_df = pd.DataFrame({
    'Test Performed': ["Anderson-Darling Test for Normality of Residuals"],
    'Test Statistic': [anderson_test_result.statistic],
    'Critical Value (5%)': [anderson_test_result.critical_values[anderson_test_result.significance_level.tolist().index(5.0)]],
    'Significance Level (%)': [5.0]
})

# Add the conclusion
alpha = 0.05
print("\nHypotheses for Anderson-Darling Test:")
print("H0: The distribution of residuals is Normal")
print("H1: The distribution of residuals is not Normal")

print("\nAnderson-Darling Test Results for Residuals:")
# Set pandas options to display floats with a reasonable number of decimal places for the statistic
pd.options.display.float_format = '{:.4f}'.format
display(ad_results_df)

print("\nInterpretation:")
if anderson_test_result.statistic > ad_results_df.loc[0, 'Critical Value (5%)']:
    print(f"As the Test Statistic ({anderson_test_result.statistic:.4f}) is greater than the Critical Value at {alpha*100}% ({ad_results_df.loc[0, 'Critical Value (5%)']:.4f}), rejeitamos a hipótese nula (a distribuição dos resíduos é Normal) ao nível de significância de 5%.")
    print("Conclusão: Há evidência estatística para concluir que a distribuição dos resíduos não é Normal.")
else:
    print(f"As the Test Statistic ({anderson_test_result.statistic:.4f}) is less than or equal to the Critical Value at {alpha*100}% ({ad_results_df.loc[0, 'Critical Value (5%)']:.4f}), falhamos em rejeitar a hipótese nula (a distribuição dos resíduos é Normal) ao nível de significância de 5%.")
    print("Conclusão: Não há evidência estatística suficiente para concluir que a distribuição dos resíduos não é Normal.")

"""## 7 - Avaliação da Homocedasticidade - Teste de Cochran

## Para avaliarmos a homocedasticidade da variância realizamos o seguinte teste de hipóteses:

H0: Variâncias dos níveis são iguais;

H1: Pelo menos uma variância diferente.

A seguir, apresentamos o teste de Teste de Cochran.
"""

import pandas as pd
import numpy as np
from scipy.stats import f

# Assuming 'df_cabeçalho' is your pandas DataFrame
# Assuming 'Nível' is the grouping variable and 'Área' is the variable to test for homoscedasticity

# Group data by 'Nível' and calculate variances of 'Área'
grouped_variances = df_cabeçalho.groupby('Nível')['Área'].var().reset_index()
grouped_variances.rename(columns={'Área': 'Variance'}, inplace=True)

# Get the maximum variance
max_variance = grouped_variances['Variance'].max()

# Get the sum of variances
sum_of_variances = grouped_variances['Variance'].sum()

# Calculate Cochran's C statistic
cochran_c_statistic = max_variance / sum_of_variances

# Number of groups (k) and replicates per group (n)
k = len(grouped_variances) # Number of levels (should be 5)
n = 3 # Number of replicates per level, as specified by the user

# Calculate p-value for Cochran's C test (approximate method using F distribution)
# This is an approximation and might not be as accurate as using exact tables or dedicated functions.
# For a more precise p-value, dedicated statistical libraries or tables for Cochran's C are recommended.
# Using an approximation based on the maximum variance and average variance:
# F-statistic approximation: ((n-1)*C) / (1-C) where C is Cochran's C
if cochran_c_statistic < 1: # Ensure C is less than 1 for the formula
    f_approx = ((n - 1) * cochran_c_statistic) / (1 - cochran_c_statistic)
    # Degrees of freedom for the approximation: df1 = k-1, df2 = k*(n-1)
    df1 = k - 1
    df2 = k * (n - 1)
    # Calculate the approximate p-value (upper tail)
    p_value_cochran = 1 - f.cdf(f_approx, df1, df2)
else:
    p_value_cochran = 0.0 # If C >= 1, it's highly likely to reject H0


# Create a DataFrame for the results
cochran_results_df = pd.DataFrame({
    'Test Performed': ["Cochran's C Test for Homoscedasticity"],
    'Test Statistic': [cochran_c_statistic],
    'Number of Replicates (n)': [n],
    'Approximate P-value': [p_value_cochran]
})

# Add the conclusion
alpha = 0.05
print("\nHypotheses for Cochran's C Test:")
print("H0: Variances of the levels are equal (Homoscedasticity)")
print("H1: At least one variance is different (Heteroscedasticity)")


print("\nCochran's C Test Results:")
# Set pandas options to display floats with a reasonable number of decimal places for the statistic
pd.options.display.float_format = '{:.4f}'.format
display(cochran_results_df)


print("\nInterpretation:")
if p_value_cochran < alpha:
    print(f"As the approximate P-valor ({p_value_cochran:.4f}) é menor que {alpha}, rejeitamos a hipótese nula (Variâncias dos níveis são iguais) ao nível de significância de 5%.")
    print("Conclusão: Há evidência estatística para concluir que pelo menos uma variância é diferente. Logo, temos um modelo heterocedástico.")
else:
    print(f"As the approximate P-valor ({p_value_cochran:.4f}) não é menor que {alpha}, falhamos em rejeitar a hipótese nula (Variâncias dos níveis são iguais) ao nível de significância de 5%.")
    print("Conclusão: Não há evidência estatística suficiente para concluir que as variâncias são diferentes. Assume-se homoscedasticidade.")

"""## 8 Valores extremos na resposta

## Nesta seção, vamos avaliar os valores extremos na resposta. Para isto, avaliamos os resíduos padronizados e os resíduos studentizados.

## 8.1 - Resíduos
Nesta seção, vamos avaliar os valores extremos na resposta. Para isto, avaliamos os resíduos padronizados e os resíduos studentizados.
"""



import pandas as pd

# Get the residuals from the fitted model (using the statsmodels OLS model)
# Assuming the 'model_sm' variable from cell TcUvkEEmfOIv holds the statsmodels OLS model
residuals = model_sm.resid

# Get standardized residuals (internally studentized)
standardized_residuals = model_sm.get_influence().resid_studentized_internal

# Get studentized residuals (externally studentized)
studentized_residuals = model_sm.get_influence().resid_studentized

# Create a DataFrame to display the residuals
residuals_df = pd.DataFrame({
    'Residuals': residuals,
    'Standardized Residuals': standardized_residuals,
    'Studentized Residuals': studentized_residuals
})

# Display the DataFrame
display(residuals_df)

"""## 9 - Pontos Influentes
Um ponto é influente se sua exclusão do ajuste da regressão causa uma mudança substancial nos valores ajustados.
"""

import pandas as pd
import statsmodels.api as sm

# Get the influence measures from the fitted model
influence = model.get_influence()

# Get Cook's distance
cooks_distance = influence.cooks_distance[0]

# Get DFBETA
dfbeta = influence.dfbeta

# Get DFFITS
dffits = influence.dffits[0]

# Create a DataFrame to display the influence measures
influence_df = pd.DataFrame({
    'Cooks_Distance': cooks_distance,
    'DFBETA_Intercept': dfbeta[:, 0],  # DFBETA for the intercept
    'DFBETA_Concentracao': dfbeta[:, 1], # DFBETA for 'Concentração mg/mL'
    'DFFITS': dffits
})

# Add residuals to the influence_df DataFrame
influence_df['Residuals'] = model.resid
influence_df['Standardized Residuals'] = influence.resid_studentized_internal
influence_df['Studentized Residuals'] = influence.resid_studentized

# Display the DataFrame
display(influence_df)

import pandas as pd

# The influence_df DataFrame already contains the DFBETA for the intercept
# We can display a table focusing on the intercept-related information

# Get the estimated intercept from the fitted model
estimated_intercept = model.intercept_

# Create a DataFrame to display the intercept and its DFBETA values
intercept_impact_df = pd.DataFrame({
    'Estimated_Intercept': estimated_intercept,
    'DFBETA_Intercept': influence_df['DFBETA_Intercept']
})

# Display the DataFrame
display(intercept_impact_df)

import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm

# Assuming the 'model_sm' variable from cell 9hv9fsWIlgyu holds the statsmodels OLS model
# Get the fitted values from the statsmodels OLS model
fitted_values = model_sm.fittedvalues

# Calculate standardized residuals
standardized_residuals = model_sm.get_influence().resid_studentized_internal

# 1. Standardized Residuals vs. Fitted Values Plot
plt.figure(figsize=(8, 4))
sns.scatterplot(x=fitted_values, y=standardized_residuals)
plt.axhline(y=0, color='r', linestyle='--') # Add line at 0
plt.axhline(y=2, color='blue', linestyle='--') # Add line at +2
plt.axhline(y=-2, color='blue', linestyle='--') # Add line at -2
plt.axhline(y=3, color='red', linestyle='--') # Add line at +3
plt.axhline(y=-3, color='red', linestyle='--') # Add line at -3
plt.title('Resíduos Padronizados vs. Valores Ajustados')
plt.xlabel('Valores Ajustados')
plt.ylabel('Resíduos Padronizados')
plt.grid(True)
plt.show()

import pandas as pd

# Utilizar as opções da biblioteca pandas para padronizar os resultados obtidos do tipo float com uma casa decimal.
pd.options.display.float_format = '{:.1f}'.format

print("Pandas display options for float format have been set to one decimal place.")

"""## 10 - Teste de Independência

## Neste item testamos a independência das observações através do seguinte teste de hipóteses:

H0: Observações são independentes;

H1: Observações não são independentes.
"""

import statsmodels.api as sm
import pandas as pd

# Assuming 'model_sm' is the fitted statsmodels OLS model from a previous cell
# If not, you would need to fit the model first:
# model_sm = ols('Área ~ Q("Concentração mg/mL")', data=df_cabeçalho).fit()

# Calculate the Durbin-Watson statistic
durbin_watson_statistic = sm.stats.stattools.durbin_watson(model_sm.resid)

# Create a DataFrame to display the result
durbin_watson_df = pd.DataFrame({
    'Test Performed': ["Durbin-Watson Test for Independence of Observations"],
    'Test Statistic': [durbin_watson_statistic]
})

print("Durbin-Watson Test Results:")
display(durbin_watson_df)

print("\nInterpretation of Durbin-Watson Statistic:")
print("The Durbin-Watson statistic ranges from 0 to 4.")
print("A value near 2 suggests no significant autocorrelation.")
print("A value less than 2 suggests positive autocorrelation.")
print("A value greater than 2 suggests negative autocorrelation.")
print("\nTo formally test for independence, compare the test statistic to lower (dL) and upper (dU) critical values from a Durbin-Watson table based on your sample size and number of predictors.")
print("\nHypotheses:")
print("H0: Observations are independent (no autocorrelation)")
print("H1: Observations are not independent (autocorrelation exists)")

"""## - Resumo do estudo de linearidade
Para finalizarmos, apresentamos uma tabela com o resumo do estudo.

# Task
Generate a summary table containing the test performed and the conclusion based on the results of the ANOVA F-test, t-tests for intercept and concentration, Anderson-Darling test for normality, and Cochran's C test for homoscedasticity.

## Gather test results

### Subtask:
Collect the key statistics and p-values (or critical values for tests like Anderson-Darling and Cochran's C) from the outputs of the executed cells for each relevant test (ANOVA for model significance, t-tests for coefficients, Anderson-Darling for normality, Cochran's C for homoscedasticity).

**Reasoning**:
Extract the relevant statistics and p-values from the previously generated outputs and store them in variables.
"""

# 1. Extract ANOVA F-test results
anova_f_statistic = anova_table.loc['Q("Concentração mg/mL")', 'F']
anova_p_value = anova_table.loc['Q("Concentração mg/mL")', 'PR(>F)']

# 2. Extract t-test p-values for coefficients
intercept_p_value = coefficients_table.loc['Intercept', 'P-valor']
concentration_p_value = coefficients_table.loc['Q("Concentração mg/mL")', 'P-valor']

# 3. Extract Anderson-Darling test results for residuals (from cell 6bkYQQzvr6O1)
# Assuming the Anderson-Darling result from cell 6bkYQQzvr6O1 is stored in `anderson_test_result`
ad_statistic = anderson_test_result.statistic
# Find the critical value at the 5% significance level
ad_critical_value_5 = anderson_test_result.critical_values[anderson_test_result.significance_level.tolist().index(5.0)]

# 4. Extract Cochran's C statistic (from cell BqI38ZXEejVw)
# Assuming the Cochran's C statistic is stored in `cochran_c`
cochran_c_statistic = cochran_c_statistic

print(f"ANOVA F-statistic: {anova_f_statistic}")
print(f"ANOVA P-value: {anova_p_value}")
print(f"Intercept t-test P-value: {intercept_p_value}")
print(f"Concentration t-test P-value: {concentration_p_value}")
print(f"Anderson-Darling Statistic (Residuals): {ad_statistic}")
print(f"Anderson-Darling Critical Value (5%): {ad_critical_value_5}")
print(f"Cochran's C Statistic: {cochran_c_statistic}")

"""## Formulate conclusions

### Subtask:
Based on standard statistical interpretation rules (comparing p-values to significance levels, test statistics to critical values), formulate a concise conclusion for each test (e.g., "Model is statistically significant", "Intercept is not statistically significant", "Residuals appear normally distributed", "Evidence of heteroscedasticity").

**Reasoning**:
Formulate a concise conclusion for each test based on the extracted statistics and a significance level of 0.05.
"""

alpha = 0.05

# 1. ANOVA F-test conclusion
if anova_p_value < alpha:
    anova_conclusion = "Model is statistically significant"
else:
    anova_conclusion = "Model is not statistically significant"

# 2. Intercept t-test conclusion
if intercept_p_value < alpha:
    intercept_conclusion = "Intercept is statistically significant"
else:
    intercept_conclusion = "Intercept is not statistically significant"

# 3. Concentration t-test conclusion
if concentration_p_value < alpha:
    concentration_conclusion = "Concentration coefficient is statistically significant"
else:
    concentration_conclusion = "Concentration coefficient is not statistically significant"

# 4. Anderson-Darling test conclusion for residuals
if ad_statistic > ad_critical_value_5:
    ad_conclusion = "Residuals do not appear normally distributed (at 5% significance level)"
else:
    ad_conclusion = "Residuals appear normally distributed (at 5% significance level)"

# 5. Cochran's C test conclusion for homoscedasticity
# Note: We cannot definitively conclude without a critical value table for Cochran's C.
# However, a high Cochran's C statistic (close to 1) suggests potential heteroscedasticity.
# A preliminary interpretation based on the value is provided.
# A more rigorous test would require comparing cochran_c_statistic to a critical value from a table.
# For a dataset with 5 groups and 3 replicates per group, the critical value at alpha=0.05
# is approximately 0.6839 according to some tables.
# Using this approximate value for preliminary interpretation:
approx_cochran_critical_value_05 = 0.6839

if cochran_c_statistic > approx_cochran_critical_value_05:
    cochran_conclusion = "Evidence of heteroscedasticity (based on preliminary comparison to approx. critical value)"
else:
    cochran_conclusion = "No strong evidence of heteroscedasticity (based on preliminary comparison to approx. critical value)"


print(f"ANOVA Conclusion: {anova_conclusion}")
print(f"Intercept Conclusion: {intercept_conclusion}")
print(f"Concentration Conclusion: {concentration_conclusion}")
print(f"Anderson-Darling Conclusion: {ad_conclusion}")
print(f"Cochran's C Conclusion: {cochran_conclusion}")

"""## Create summary table

### Subtask:
Construct a pandas DataFrame with two columns: "Test Performed" and "Conclusion". Populate this DataFrame with the names of the tests and their corresponding conclusions.

**Reasoning**:
Construct a pandas DataFrame with the test names and conclusions.
"""

# Create a list of test names
test_names = [
    "ANOVA F-test for Model Significance",
    "t-test for Intercept",
    "t-test for Concentration Coefficient",
    "Anderson-Darling Test for Residual Normality",
    "Cochran's C Test for Homoscedasticity"
]

# Create a list of corresponding conclusions
conclusions = [
    anova_conclusion,
    intercept_conclusion,
    concentration_conclusion,
    ad_conclusion,
    cochran_conclusion
]

# Create the DataFrame
summary_table = pd.DataFrame({
    "Test Performed": test_names,
    "Conclusion": conclusions
})

# Display the summary table
display(summary_table)

"""## Display summary table

### Subtask:
Display the created summary table.

**Reasoning**:
Display the created summary table DataFrame.
"""

display(summary_table)

"""## Summary:

### Data Analysis Key Findings

*   The ANOVA F-test for the model's significance yielded a p-value of approximately 3.11e-17, indicating the model is statistically significant.
*   The t-test for the intercept coefficient had a p-value of approximately 0.722, suggesting the intercept is not statistically significant at the 5% level.
*   The t-test for the concentration coefficient resulted in a p-value of approximately 3.11e-17, indicating the concentration coefficient is statistically significant.
*   The Anderson-Darling test for residual normality produced a statistic (0.300) lower than the 5% critical value (0.681), suggesting the residuals appear normally distributed.
*   Cochran's C statistic was approximately 0.569. Based on a preliminary comparison to an approximate critical value, there is no strong evidence of heteroscedasticity.

### Insights or Next Steps

*   The statistical significance of the concentration coefficient suggests that concentration is a strong predictor in the model.
*   Further investigation into the non-significant intercept might be warranted depending on the context of the analysis.

"""

